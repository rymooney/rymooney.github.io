[
  {
    "objectID": "TextAnalysis.html",
    "href": "TextAnalysis.html",
    "title": "Text Analysis",
    "section": "",
    "text": "The Task\nToday, I will be practicing my text analysis using str_*() commands, regular expressions, and plotting character-based data! To do this, I will be analyzing character data from all of The New York Times’ headlines from years 1996-2006.\n\n\nThe Data\nThe data is sample dataset containing headlines from The New York Times, compiled by Professor Amber E. Boydstun at the University of California, Davis. The dataset can be accessed in the RTextTools library on R from the RTextTools package. The data is in the library in a data frame called NYTimes.\n\nlibrary(tidyverse)\nlibrary(RTextTools) \ndata(NYTimes)\nas_tibble(NYTimes)\n\n# A tibble: 3,104 × 5\n   Article_ID Date      Title                                 Subject Topic.Code\n        &lt;int&gt; &lt;fct&gt;     &lt;fct&gt;                                 &lt;fct&gt;        &lt;int&gt;\n 1      41246 1-Jan-96  Nation's Smaller Jails Struggle To C… Jails …         12\n 2      41257 2-Jan-96  FEDERAL IMPASSE SADDLING STATES WITH… Federa…         20\n 3      41268 3-Jan-96  Long, Costly Prelude Does Little To … Conten…         20\n 4      41279 4-Jan-96  Top Leader of the Bosnian Serbs Now … Bosnia…         19\n 5      41290 5-Jan-96  BATTLE OVER THE BUDGET: THE OVERVIEW… Battle…          1\n 6      41302 7-Jan-96  South African Democracy Stumbles on … politi…         19\n 7      41314 8-Jan-96  Among Economists, Little Fear on Def… econom…          1\n 8      41333 10-Jan-96 BATTLE OVER THE BUDGET: THE OVERVIEW… budget…          1\n 9      41344 11-Jan-96 High Court Is Cool To Census Change   census…         20\n10      41355 12-Jan-96 TURMOIL AT BARNEYS: THE DIFFICULTIES… barney…         15\n# ℹ 3,094 more rows\n\n\nThe libraries I will need:\n\nlibrary(tidyverse) \nlibrary(ggrepel)\nlibrary(stringr)\nlibrary(lubridate)\n\n\n\nLet’s analyze!\nLet’s see what years the dataset has.\n\nNYTimes_dates &lt;- NYTimes |&gt;\n  mutate(date_as_dmy = dmy(Date)) |&gt;\n  summarize(\n    earliestdate = min(date_as_dmy, na.rm = TRUE),\n    latestdate   = max(date_as_dmy, na.rm = TRUE)\n  )\n\nNYTimes_dates\n\n  earliestdate latestdate\n1   1996-01-01 2006-12-31\n\n\nFirst, I know that President Bush was a hot topic during these years.\nLet’s see the distribution of this over the years included in this dataset. I also want to exclude the mention of bush fires, which also took place and may have been talked about on NYT often, so I will reflect that in my regular expression using a negative look-forward!\n\nbush_mentioned &lt;- NYTimes |&gt;\n  mutate(Title_lower = str_to_lower(Title))|&gt;\n  mutate(date = dmy(Date))|&gt;\n  mutate(year = year(date))|&gt;\n  filter(str_detect(Title_lower, \"\\\\bbush\\\\b(?!\\\\s*fires)\")) |&gt;\n  count(year)\n\nbush_mentioned\n\n  year  n\n1 1999  2\n2 2000 15\n3 2001 32\n4 2002 20\n5 2003 16\n6 2004 20\n7 2005 13\n8 2006  8\n\nggplot(bush_mentioned, aes(x = year, y = n)) +\n  geom_line() +\n  labs(\n    title = \"Presence of 'Bush' in NYT Headlines yearly (1996–2006)\",\n    x = \"Year\",\n    y = \"summed count per year\"\n  ) \n\n\n\n\n\n\n\n\nThere was a peak in the mentions of “Bush” in the year 2001. This makes sense due to his inauguration as President of the United States and the September 11th both taking place that year.\nOn the topic of presidents, let’s quantify how much different presidents were talked about in the New York Times across the time frame represented by this data. I will use another regular expression to find the words “Bush”, “Clinton”, and “Obama”, excluding the search for “bush fire”, mentions of “Hillary Clinton”, and “Michelle Obama”, as for this analysis I am only looking for information on the presidents. To do this, I will make use of a couple of lookarounds, which are proving to be quite useful for specifying data!\n\npresident_names &lt;- NYTimes |&gt;\n  mutate(\n    titles_lower = str_to_lower(Title),\n    president = str_extract(\n      titles_lower,\n      \"(?&lt;!laura\\\\s)\\\\bbush(?!\\\\s*fires?)\\\\b|(?&lt;!hillary\\\\s)\\\\bclinton\\\\b|\n      (?&lt;!michelle\\\\s)\\\\bobama\\\\b\")) |&gt;\n  select(titles_lower, president) |&gt;\n  filter(!is.na(president))|&gt;\n  group_by(president)|&gt;\n  summarize(count=n())\n\n\npresident_names |&gt;\n  ggplot(aes(x = president, y = count)) +\n  geom_col()+\n  labs(\n    title = 'Mentions of \"Bush\" and \"Clinton\" in NYT Headlines (1996–2006)',\n    x = \"President\",\n    y = \"Count\"\n  ) \n\n\n\n\n\n\n\n\nSo, Bush was mentioned more than Clinton in this dataset from the years 1996 to 2006. Both were mentioned more than Obama, with 0 mentions.This makes sense as Obama only started running for election in 2007, right after this dataset ends. However, it is a bit surprising that he wasn’t mentioned at all prior to the year before his election. Curious!\nFinally, I am interested to see how the timing of the mentions of each of these presidents compares and if I can pull out historical dates from the peaks in the following plot.\n\npresidents_mentioned &lt;- NYTimes |&gt;\n  mutate(Title_lower = str_to_lower(Title)) |&gt;\n  mutate(date = dmy(Date)) |&gt;\n  mutate(year = year(date)) |&gt;\n  filter(str_detect(Title_lower, \"\\\\b(bush(?!\\\\s*fires?)|clinton)\\\\b\")) |&gt;\n  mutate(\n    president = ifelse(\n      str_detect(Title_lower, \"\\\\bbush(?!\\\\s*fires?)\\\\b\"),\n      \"Bush\", \"Clinton\")) |&gt;\n  group_by(year, president) |&gt;\n  summarize(n = n(), .groups = \"drop\")\n\nggplot(presidents_mentioned, aes(x = year, y = n, color = president)) +\n  geom_line() +\n  geom_point()+\n  scale_x_continuous(breaks = seq(1996, 2006, by = 1)) +\n  labs(\n    title = \"Presence of 'Bush' and 'Clinton' in NYT Headlines\",\n    subtitle= \"1996-2006\",\n    x = \"Year\",\n    y = \"Summed count per year\",\n    color = \"President\"\n  )\n\n\n\n\n\n\n\n\nWe can see that the mentions of “Clinton” peak in 1998, when he was impeached. Mentions of “Bush” begin rising shortly after, with this pattern starting to get mentioned in 1999, when his campaign for presidential election was occuring and leading to his victory in 2000. Bush was inaugurated in 2001 and that year is also when the September 11th attacks took place, so mentions of Bush were extremely high that year. There is another peak in 2004 in “Bush” mentions again, given his re-election as president.\nWe can use text data to see how much different topics are being talked about in the media, which is a very important thing to know, and it can be useful to identify specific periods of interest.\nAnd… that’s it for today!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ryan Mooney",
    "section": "",
    "text": "Hi there! I am Ryan, a student at Pomona College majoring in Molecular Biology and minoring in Data Science. I am an aspiring biomedical researcher, with keen interests in cancer biology and immuno-oncology. Sequencing has revolutionized how we analyze genetic information, so minoring in data science has provided me with invaluable skills to approach translational research questions. I love learning, and pursuing a career in research is how I plan to continue doing what I love (to learn!). I am a rather crafty person, and I particularly enjoy knitting, sewing, and collaging.\nCheck out the pages on my site to learn more about me!"
  },
  {
    "objectID": "tidytuesday10_28.html",
    "href": "tidytuesday10_28.html",
    "title": "Selected Literary Prizes",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.2     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.1.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(praise)\nlibrary(shiny)\nlibrary(tidytuesdayR)\nlibrary(ggalluvial)\n#| message: false\n#| warning: false\n\nprizes &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-10-28/prizes.csv') |&gt; \n  mutate(highest_degree = ifelse(is.na(highest_degree), \"unknown\", \n                                 highest_degree)) |&gt; \n  mutate(highest_degree = forcats::fct_recode(highest_degree,  \n                                 \"a none\" = \"none\", \"b unknown\" = \"unknown\", \n                                 \"c Diploma\" = \"Diploma\", \n                                 \"d Certificate of Education\" = \"Certificate of Education\", \n                                 \"e Bachelors\" = \"Bachelors\", \n                                 \"f Masters\" = \"Masters\", \n                                 \"g Juris Doctor\" = \"Juris Doctor\", \n                                 \"h MD\" = \"MD\", \n                                 \"i Doctorate\" = \"Doctorate\",\n                                 \"j Postgraduate\" = \"Postgraduate\"))\n\nRows: 952 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (20): prize_alias, prize_name, prize_institution, prize_genre, person_id...\ndbl  (2): prize_id, prize_year\nlgl  (1): uk_residence\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWe are going to make a sankey plot.\n\nbooker &lt;- prizes |&gt;\n  filter(prize_name == \"Booker Prize\") |&gt;\n  ggsankey::make_long(gender, ethnicity_macro, highest_degree) \n\nWarning: attributes are not identical across measure variables; they will be\ndropped\n\nbooker\n\n# A tibble: 249 × 4\n   x               node          next_x          next_node    \n   &lt;fct&gt;           &lt;chr&gt;         &lt;fct&gt;           &lt;chr&gt;        \n 1 gender          man           ethnicity_macro White British\n 2 ethnicity_macro White British highest_degree  e Bachelors  \n 3 highest_degree  e Bachelors   &lt;NA&gt;            &lt;NA&gt;         \n 4 gender          man           ethnicity_macro Irish        \n 5 ethnicity_macro Irish         highest_degree  e Bachelors  \n 6 highest_degree  e Bachelors   &lt;NA&gt;            &lt;NA&gt;         \n 7 gender          man           ethnicity_macro Asian        \n 8 ethnicity_macro Asian         highest_degree  e Bachelors  \n 9 highest_degree  e Bachelors   &lt;NA&gt;            &lt;NA&gt;         \n10 gender          man           ethnicity_macro Asian        \n# ℹ 239 more rows\n\n\n\nlibrary(ggsankey)\n  \np1 &lt;- ggplot(booker, aes(x = x, next_x = next_x, \n                node = node, next_node = next_node, \n                fill = factor(node), label = node)) +\n  geom_sankey(flow.alpha = 0.6, node.color = \"gray30\") +\n  geom_sankey_label(size = 3, color = \"white\", fill = \"gray40\") +\n  scale_fill_viridis_d() +\n  theme_sankey(base_size = 18) +\n  labs(x = NULL,\n       title = \"Booker Prize\") +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = .5))\n\n\nbailey &lt;- prizes |&gt;\n  filter(prize_name == \"Baillie Gifford Prize for Non-Fiction\") |&gt;\n  ggsankey::make_long(gender, ethnicity_macro, highest_degree) \n\nWarning: attributes are not identical across measure variables; they will be\ndropped\n\nbailey\n\n# A tibble: 423 × 4\n   x               node          next_x          next_node    \n   &lt;fct&gt;           &lt;chr&gt;         &lt;fct&gt;           &lt;chr&gt;        \n 1 gender          man           ethnicity_macro White British\n 2 ethnicity_macro White British highest_degree  b unknown    \n 3 highest_degree  b unknown     &lt;NA&gt;            &lt;NA&gt;         \n 4 gender          man           ethnicity_macro Jewish       \n 5 ethnicity_macro Jewish        highest_degree  b unknown    \n 6 highest_degree  b unknown     &lt;NA&gt;            &lt;NA&gt;         \n 7 gender          man           ethnicity_macro White British\n 8 ethnicity_macro White British highest_degree  e Bachelors  \n 9 highest_degree  e Bachelors   &lt;NA&gt;            &lt;NA&gt;         \n10 gender          man           ethnicity_macro White British\n# ℹ 413 more rows\n\n\n\np2 &lt;- ggplot(bailey, aes(x = x, next_x = next_x, \n                node = node, next_node = next_node, \n                fill = factor(node), label = node)) +\n  geom_sankey(flow.alpha = 0.6, node.color = \"gray30\") +\n  geom_sankey_label(size = 3, color = \"white\", fill = \"gray40\") +\n  scale_fill_viridis_d() +\n  theme_sankey(base_size = 18) +\n  labs(x = NULL,\n       title = \"Baillie Gifford Prize for Non-Fiction\") +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = .5))\n\n\njames &lt;- prizes |&gt;\n  filter(prize_name == \"James Tait Black Prize for Fiction\") |&gt;\n  ggsankey::make_long(gender, ethnicity_macro, highest_degree) \n\nWarning: attributes are not identical across measure variables; they will be\ndropped\n\np3 &lt;- ggplot(james, aes(x = x, next_x = next_x, \n                node = node, next_node = next_node, \n                fill = factor(node), label = node)) +\n  geom_sankey(flow.alpha = 0.6, node.color = \"gray30\") +\n  geom_sankey_label(size = 3, color = \"white\", fill = \"gray40\") +\n  scale_fill_viridis_d() +\n  theme_sankey(base_size = 18) +\n  labs(x = NULL,\n       title = \"James Tait Black Prize for Fiction\") +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = .5))\n\n\nscience &lt;- prizes |&gt;\n  filter(prize_name == \"BSFA Award for Best Novel\") |&gt;\n  ggsankey::make_long(gender, ethnicity_macro, highest_degree) \n\nWarning: attributes are not identical across measure variables; they will be\ndropped\n\np4 &lt;- ggplot(science, aes(x = x, next_x = next_x, \n                node = node, next_node = next_node, \n                fill = factor(node), label = node)) +\n  geom_sankey(flow.alpha = 0.6, node.color = \"gray30\") +\n  geom_sankey_label(size = 3, color = \"white\", fill = \"gray40\") +\n  scale_fill_viridis_d() +\n  theme_sankey(base_size = 18) +\n  labs(x = NULL,\n       title = \"BSFA Award for Best Novel\") +\n  theme(legend.position = \"none\",\n        plot.title = element_text(hjust = .5))\n\n\np1\n\n\n\n\n\n\n\n\n\np2\n\n\n\n\n\n\n\n\n\np3\n\n\n\n\n\n\n\n\n\np4"
  },
  {
    "objectID": "simulation.html",
    "href": "simulation.html",
    "title": "Simulation",
    "section": "",
    "text": "The Task\nToday, my goal is to simulate probabilities related to the accumulation of genetic mutations in somatic cells, which are key drivers of oncogenesis. The mutations being modeled arise from spontaneous events in cells and environmental conditions. I will be modeling these mutations from a single cell the undergoes n mitotic divisions and yields a final cell lineage. At each division, I will assume there is an equal probability, prob, that a mutation occurs. Once any mutation happens, the lineage is considered “mutated” and is no longer considered a wild type population. We want to estimate the probability that the lineage has at least 1 mutation after n divisions.\n\n\nBeginning the model\nTo begin, I will set up a function to detect mutations. To do this, I will write a function with two inputs, one being the number of divisions, n_divisions, that we can model the cell dividing n times, and the second being prob, the probability of a mutation occuring at each division. For each division, I will generate a random uniform number between 0 and 1 with runif(). Then, I will compare this number with the probability value, prob, and say that there was a mutation if the random uniform number generated at that division is less than the probability that there is a mutation at that division. This will create a logical vector. If the sum of this logical vector is greater than 0, then there is a mutation in that simulated lineage.\n\nlibrary(tidyverse)\nset.seed(4747)\n\nhas_mutation &lt;- function(n_divisions, prob){\n  random &lt;- runif(n_divisions)\n  mutation_flag &lt;- random &lt; prob\n  total_mutations &lt;- sum(mutation_flag)\n  ifelse(total_mutations &gt; 0, TRUE, FALSE)\n}\n\nThe above logic can be used to simulate larger numbers of lineages. To start, we will simulate the probability of 0.001, meaning that each cell division has a 0.1% chance of generating a new mutation that persists in the lineage. I will simulate 10000 starting cells independently going through 50 cell divisions. The first map will repeat the next map 50 times, simulating each division. The map_lgl() simulates n_cells cells going through a division and repeats that process 10000 times, and sums the has_mutation() function defined above on each division This inner map_lgl() function returns TRUE if a lineage picked up at least one mutation, and returns FALSE otherwise. The combinations of the maps, while confusing at first, was the only way I figured out how to get multiple simulated cells going through mutliple division cycles. The final tibble() summarizes the results for each of the 10000 cells after each division cycle, and calculates the proportion of TRUE values after that division cycle. This gives a 2x1 data frame for each division. The final pipe into list_rbind() gives us a final data frame of the proportion of lineages that have a mutation after each division.\n\nset.seed(4747)\nprob_0 &lt;- 0.001\nn_cells &lt;- 10000\nnumber_of_divisions &lt;- 1:50\n\nresults &lt;- map(number_of_divisions, function(n) {\n  outcomes &lt;- map_lgl(1:n_cells, .f = ~ has_mutation(n_divisions = n, prob = prob_0))\n  tibble(divisions = n, prob_mutated = mean(outcomes))\n  }) |&gt; \n  list_rbind()\n\nresults\n\n# A tibble: 50 × 2\n   divisions prob_mutated\n       &lt;int&gt;        &lt;dbl&gt;\n 1         1       0.0017\n 2         2       0.0019\n 3         3       0.0028\n 4         4       0.0037\n 5         5       0.005 \n 6         6       0.0062\n 7         7       0.0063\n 8         8       0.0072\n 9         9       0.01  \n10        10       0.0086\n# ℹ 40 more rows\n\n\n\n\nLet’s visualize!\nLet’s visualize what this data frame looks like graphically as mutations are accumulated across the simulated cell populations.\n\nggplot(results, aes(x = divisions, y = prob_mutated * 100)) +\n  geom_line() +\n  geom_point() +\n  scale_y_continuous(limits = c(0, 100)) +\n  labs(\n    title = \"Probability a cell lineage has at least one mutation\",\n    subtitle = \"Mutation probability of 0.1% per division for 10,000 starting cells\",\n    x = \"Number of mitotic divisions\",\n    y = \"Percent of lineages with at least 1 mutation\"\n  )\n\n\n\n\n\n\n\n\nLet’s check how this plot changes with a a higher frequency of mutation, say a 1% chance of a mutation each cell division.\n\nset.seed(4747)\nprob_1 &lt;- 0.01\nn_cells &lt;- 10000\nnumber_of_divisions &lt;- 1:50\n\nresults_1 &lt;- map(number_of_divisions, function(n) {\n  outcomes &lt;- map_lgl(1:n_cells, .f = ~ has_mutation(n_divisions = n, prob = prob_1))\n  tibble(divisions_1 = n, prob_mutated_1 = mean(outcomes))\n  }) |&gt; \n  list_rbind()\n\nresults\n\n# A tibble: 50 × 2\n   divisions prob_mutated\n       &lt;int&gt;        &lt;dbl&gt;\n 1         1       0.0017\n 2         2       0.0019\n 3         3       0.0028\n 4         4       0.0037\n 5         5       0.005 \n 6         6       0.0062\n 7         7       0.0063\n 8         8       0.0072\n 9         9       0.01  \n10        10       0.0086\n# ℹ 40 more rows\n\nresults_1\n\n# A tibble: 50 × 2\n   divisions_1 prob_mutated_1\n         &lt;int&gt;          &lt;dbl&gt;\n 1           1         0.0104\n 2           2         0.0204\n 3           3         0.0296\n 4           4         0.0379\n 5           5         0.0481\n 6           6         0.0566\n 7           7         0.0696\n 8           8         0.0764\n 9           9         0.0876\n10          10         0.0911\n# ℹ 40 more rows\n\n\n\nggplot(results_1, aes(x = divisions_1, y = prob_mutated_1 * 100)) +\n  geom_line() +\n  geom_point() +\n  scale_y_continuous(limits = c(0, 100)) +\n  labs(\n    title = \"Probability a cell lineage has at least one mutation\",\n    subtitle = \"Mutation probability of 1% per division for 10000 starting cells\",\n    x = \"Number of mitotic divisions\",\n    y = \"Percent of lineages with at least 1 mutation\"\n  )\n\n\n\n\n\n\n\n\nWow. That’s a lot of accumulated mutations! Luckily, our cells do not have a 1% chance of accumulating a meaningful, harmful, and disruptive mutation each time they divide (if they did, we likely wouldn’t exist). Let’s use a more biologically relevant proportion of mutation.\nI’ll model a 1e-6 per-division probability that a daughter cell acquires a mutation that is not just silent, but actually alters fitness in a biologically meaningful way. This is a reasonable number, modeling a mutation in any meaningful, harmful mutation across a panel of key genes/pathways.\n\nset.seed(4747)\nprob_2 &lt;- 1e-6\nn_cells &lt;- 10000\nnumber_of_divisions &lt;- 1:50\n\nresults_2 &lt;- map(number_of_divisions, function(n) {\n  outcomes &lt;- map_lgl(1:n_cells, .f = ~ has_mutation(n_divisions = n, prob = prob_2))\n  tibble(divisions_2 = n, prob_mutated_2 = mean(outcomes))\n  }) |&gt; \n  list_rbind()\n\n\nresults_2\n\n# A tibble: 50 × 2\n   divisions_2 prob_mutated_2\n         &lt;int&gt;          &lt;dbl&gt;\n 1           1              0\n 2           2              0\n 3           3              0\n 4           4              0\n 5           5              0\n 6           6              0\n 7           7              0\n 8           8              0\n 9           9              0\n10          10              0\n# ℹ 40 more rows\n\n\nLooking at the above data frame, we know these mutation frequencies will be close to zero. So, I will zoom in on the graph to see the actual trend (i.e, the y-axis here will not go from 0 to 100).\n\nggplot(results_2, aes(x = divisions_2, y = prob_mutated_2)) +\n  geom_line() +\n  geom_point() +\n  labs(\n    title = \"Probability a cell lineage has at least one mutation\",\n    subtitle = \"Mutation probability of 0.0001% per division for 10000 starting cells\",\n    x = \"Number of mitotic divisions\",\n    y = \"Percent of lineages with at least 1 mutation\"\n  )\n\n\n\n\n\n\n\n\nThis is very close to 0. And that’s a good thing! Most cell divisions faithfully copy DNA with no meaningful changes. Once in tens of thousands or millions of divisions, a driver mutation pops up — a mutation that actually changes cell fitness and can lead to downstream problems. That rare event can seed a clone that can later expand, but the initial occurrence is tremendously rare, as shown above.\n\n\nThat’s it!\nThanks for joining me on my first simulation today! That was a lot of fun."
  },
  {
    "objectID": "UNESCO.html",
    "href": "UNESCO.html",
    "title": "UNESCO",
    "section": "",
    "text": "library(tidyverse)\n\n\nThe Data\nI wanted to explore a simple data set comparing UNESCO world heritage sites in Norway, Denmark, and Sweden. The original data is from UNESCO and was downloaded from TidyTuesday. The data also comes from the {pixarfilms} R package by Eric Leung.\n\nunesco &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2024/2024-02-06/heritage.csv')\n\n\nunesco2 &lt;- unesco |&gt;\n  pivot_longer(\n    cols = c(`2004`, `2022`),\n    names_to = \"year\",\n    values_to = \"number_of_sites\"\n  )\n\n\n\nLet’s plot the data!\n\nggplot(unesco2, aes(x = country, y = number_of_sites, color = year)) +\n  geom_point(size = 3) +\n  labs(\n    title = \"UNESCO World Heritage Sites\",\n    x = \"Country\",\n    y = \"Number of Sites\"\n  )\n\n\n\n\n\n\n\n\nShowing the number of World Heritage Sites in Norway, Denmark, and Sweden across 2004 to 2022.\nImage credit: Ryan Mooney"
  },
  {
    "objectID": "data-viz.html",
    "href": "data-viz.html",
    "title": "Data Viz",
    "section": "",
    "text": "This is my data visualization page, where I upload my data visualizations done on TidyTuesday data."
  },
  {
    "objectID": "pixar.html",
    "href": "pixar.html",
    "title": "pixar",
    "section": "",
    "text": "library(tidyverse)\n\n\nThe Data\nLet’s explore a data set about the ratings of pixar films Pixar films; the data here is from the TidyTuesday repo and the original data is from Wikipedia.\n\npixar_ratings &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-03-11/public_response.csv')\n\n\n\nLet’s plot it!\n\npixar_ratings_long &lt;- pixar_ratings |&gt;\n  pivot_longer(\n    cols = c(rotten_tomatoes, metacritic, critics_choice),\n    names_to = \"rating_source\",\n    values_to = \"score\"\n  )|&gt;\n  filter(!is.na(score)) \n\nggplot(pixar_ratings_long, aes(x = film, y = score, color = rating_source)) +\n  geom_point(size = 3) +\n  geom_line(aes(group = rating_source)) +\n  labs(\n    title = \"Pixar Movie Ratings\",\n    x = \"Film\",\n    y = \"Score\",\n    color = \"Rating Source\"\n  ) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1)\n  )"
  },
  {
    "objectID": "permutation.html",
    "href": "permutation.html",
    "title": "Permutation Test",
    "section": "",
    "text": "The Task\nToday, I will be running a permutation test using a data set from William Wolberg, Olvi Mangasarian. Nick Street, and W. Street in their paper “Nuclear feature extraction for breast tumor diagnosis” 1993 Published in Electronic imaging. The dataset was downloaded from UC Irvine Machine Learning Repository. The goal is to look at whether there is a correlation between diagnosis of a tumor and tumor size.\n#The Data The data set compiled many features that were computed from a digitized image of a fine needle aspirate (FNA) of 529 breast masses. They recorded the following data:\n\nID number\nDiagnosis (M = malignant, B = benign)\n\nTen real-valued features are computed for each cell nucleus:\na) radius (mean of distances from center to points on the perimeter)\nb) texture (standard deviation of gray-scale values)\nc) perimeter\nd) area\ne) smoothness (local variation in radius lengths)\nf) compactness (perimeter^2 / area - 1.0)\ng) concavity (severity of concave portions of the contour)\nh) concave points (number of concave portions of the contour)\ni) symmetry \nj) fractal dimension (\"coastline approximation\" - 1)\nThey provide standard errors and the “worst”, or the most extreme, value for each of the variables for each sample.\n\nlibrary(tidyverse)\nlibrary(readr)\nlibrary(here)\n\ntumor_data &lt;- read_csv(here(\"data\", \"wdbc.data\"))\n\ncolnames(tumor_data) &lt;- c(\n  \"id\", \"diagnosis\",\n  \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\",\n  \"compactness_mean\", \"concavity_mean\", \"concave_points_mean\", \"symmetry_mean\", \"fractal_dimension_mean\",\n  \n  \"radius_se\", \"texture_se\", \"perimeter_se\", \"area_se\", \"smoothness_se\",\n  \"compactness_se\", \"concavity_se\", \"concave_points_se\", \"symmetry_se\", \"fractal_dimension_se\",\n  \n  \"radius_worst\", \"texture_worst\", \"perimeter_worst\", \"area_worst\", \"smoothness_worst\",\n  \"compactness_worst\", \"concavity_worst\", \"concave_points_worst\", \"symmetry_worst\", \"fractal_dimension_worst\")\n\ntumor_data\n\n# A tibble: 568 × 32\n         id diagnosis radius_mean texture_mean perimeter_mean area_mean\n      &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;        &lt;dbl&gt;          &lt;dbl&gt;     &lt;dbl&gt;\n 1   842517 M                20.6         17.8          133.      1326 \n 2 84300903 M                19.7         21.2          130       1203 \n 3 84348301 M                11.4         20.4           77.6      386.\n 4 84358402 M                20.3         14.3          135.      1297 \n 5   843786 M                12.4         15.7           82.6      477.\n 6   844359 M                18.2         20.0          120.      1040 \n 7 84458202 M                13.7         20.8           90.2      578.\n 8   844981 M                13           21.8           87.5      520.\n 9 84501001 M                12.5         24.0           84.0      476.\n10   845636 M                16.0         23.2          103.       798.\n# ℹ 558 more rows\n# ℹ 26 more variables: smoothness_mean &lt;dbl&gt;, compactness_mean &lt;dbl&gt;,\n#   concavity_mean &lt;dbl&gt;, concave_points_mean &lt;dbl&gt;, symmetry_mean &lt;dbl&gt;,\n#   fractal_dimension_mean &lt;dbl&gt;, radius_se &lt;dbl&gt;, texture_se &lt;dbl&gt;,\n#   perimeter_se &lt;dbl&gt;, area_se &lt;dbl&gt;, smoothness_se &lt;dbl&gt;,\n#   compactness_se &lt;dbl&gt;, concavity_se &lt;dbl&gt;, concave_points_se &lt;dbl&gt;,\n#   symmetry_se &lt;dbl&gt;, fractal_dimension_se &lt;dbl&gt;, radius_worst &lt;dbl&gt;, …\n\n\n\n\nThe Hypotheses\nToday, I will be investigating the relationship between two variables: diagnosis (whether the tumor is malignant or benign) and tumor area. These variables are interesting because malignancy and benign tumors have different characteristics: malignant tumors are cancerous, they grow uncontrollably, invade nearby tissues, and can spread to other parts of the body, and benign tumors are non-cancerous slow-growing, don’t invade surrounding tissue, and are often treatable or harmless. Looking at cell area (and other variables) is interesting because it could give insight into which features can best be used to predict malignancy. The null hypothesis is that benign tumors and malignant tumors have cells of the same average area. The alternative hypothesis is that malignant tumors have larger average cell areas.\nThe statistic to test this difference will be difference in means between area in the benign and malignant tumor samples.\n\ntumor_data |&gt; \n  group_by(diagnosis) |&gt; \n  summarize(ave_area = mean(area_mean))|&gt;\n  mutate(diagnosis = factor(diagnosis, levels = c(\"B\", \"M\")))\n\n# A tibble: 2 × 2\n  diagnosis ave_area\n  &lt;fct&gt;        &lt;dbl&gt;\n1 B             463.\n2 M             978.\n\n\nHere is a visual of the original relationship in the data.\n\ntumor_data |&gt; \n  ggplot(aes(x = diagnosis, y = area_mean)) + \n  geom_boxplot()\n\n\n\n\n\n\n\n\nSo, it looks like the mean area of malignant tumor cells is larger than that of benign tumor cells. However, is that generalizable to other breast tumors? Off to the permutation test!\n\n\nThe permutation test\nTo start, I will generate a null sample distribution.\n\nperm_data &lt;- function(rep, data) {\n  data |&gt;\n    select(diagnosis, area_mean) |&gt;\n    mutate(area_perm = sample(area_mean, replace = FALSE)) |&gt;\n    group_by(diagnosis) |&gt;\n    summarize(\n      obs_mean  = mean(area_mean),\n      perm_mean = mean(area_perm),\n      .groups = \"drop\") |&gt;\n    summarize(\n      obs_mean_diff  = diff(obs_mean),\n      perm_mean_diff = diff(perm_mean),\n      rep = rep\n    )\n}\n\nmap(c(1:10000), perm_data, data = tumor_data) |&gt; \n  list_rbind()\n\n# A tibble: 10,000 × 3\n   obs_mean_diff perm_mean_diff   rep\n           &lt;dbl&gt;          &lt;dbl&gt; &lt;int&gt;\n 1          515.          30.5      1\n 2          515.         -12.6      2\n 3          515.         -58.4      3\n 4          515.          15.2      4\n 5          515.         -34.7      5\n 6          515.         -40.1      6\n 7          515.           5.15     7\n 8          515.         -46.0      8\n 9          515.          27.5      9\n10          515.         -31.0     10\n# ℹ 9,990 more rows\n\n\n\nset.seed(47)\nperm_stats &lt;- \n  map(c(1:10000), perm_data, data = tumor_data) |&gt; \n  list_rbind() \n\nperm_stats |&gt; \n  ggplot(aes(x = perm_mean_diff)) + \n  geom_histogram(binwidth = 5) + \n  geom_vline(aes(xintercept = obs_mean_diff), color = \"red\")\n\n\n\n\n\n\n\n\n\nperm_stats |&gt; \n    summarize(p_val = mean(perm_mean_diff &gt; obs_mean_diff))\n\n# A tibble: 1 × 1\n  p_val\n  &lt;dbl&gt;\n1     0"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi and welcome to my site!\n\nMy background\nI am originally from Denver, Colorado. I have three older sisters, who are some of my biggest inspirations. After graduating high school in 2023, I went to Pomona College, where I expect to graduate in 2027 with a Bachelor of Arts in Molecular Biology and a minor in Data Science.\n\n\nMy research experience\nAt Pomona College, I have been involved in research since my freshman year. In Dr. Malkiat Johal’s lab, I work to quantify biomolecular interactions. I have worked on various projects leveraging surface chemistry instruments like Quartz Crystal Microgravimetry with Dissipation Monitoring (QCM-D) and Surface Plasmon Resonance (SPR). My work over my first-year was on the QCM-D, where we quantified off-target effects of beta-cyclodextrin drugs on biomimetic lipid membranes, which was published in Langmuir. I then switched gears over the summer and worked with the SPR to develop a novel method using chemical kinetics data to determine the molecular weight of polyelectrolytes (this work has been submitted, and we are waiting to hear back from the reviewers!). I am working on developing and finalizing some other projects related to enzyme inhibition and immuno-oncological interactions, so stay tuned for updates!\nI have also been fortunate enough to engage in research at Memorial Sloan Kettering Cancer Center under the guidance of Dr. Michael Gormally and Dr. Christopher Klebanoff. Here, I gained training in immuno-oncology and contributed to a project with the goals of designing immunotherapies for solid-phase cancers. Specificaly, this project involved working with cell culture, ELISA, IncuCyte live-cell imaging, and flow cytometry to evaluate and quantify the killing of cancer cells by T cells transduced with cancer neoepitope-specific T cell receptors. I got to experiment with armoring our T cells with additional potency, in the form of constitutive cytokine (IL-18) secretion and by engineering CD8 co-receptor expression. Our results were tremendously promising, and in vivo trials of our work are beginning now!"
  }
]